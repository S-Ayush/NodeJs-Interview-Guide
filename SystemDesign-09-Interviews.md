# Chapter 9: System Design Interviews

## 9.1 Introduction

System design interviews assess your ability to design large-scale distributed systems. Unlike coding interviews, there's no single "correct" answerâ€”it's about demonstrating systematic thinking, trade-off analysis, and communication skills.

### What Interviewers Look For

```
âœ“ Structured Approach
  - Clear methodology
  - Organized thinking
  - Comprehensive coverage

âœ“ Technical Depth
  - Understanding of fundamentals
  - Knowledge of trade-offs
  - Real-world experience

âœ“ Communication
  - Clear explanations
  - Active listening
  - Collaborative discussion

âœ“ Problem-Solving
  - Identify bottlenecks
  - Propose solutions
  - Handle constraints

âœ“ Practical Knowledge
  - Scalability patterns
  - Production systems
  - Technology choices
```

### Interview Structure (45-60 minutes)

```
0-5 min:    Requirements clarification
5-10 min:   Capacity estimation
10-25 min:  High-level design
25-40 min:  Deep dive on components
40-45 min:  Trade-offs and wrap-up
```

---

## 9.2 The REDSAD Framework

A systematic approach to tackle any system design problem.

```
R - Requirements (Functional & Non-Functional)
E - Estimation (Users, QPS, Storage, Bandwidth)
D - Design High-Level (Components, Data flow)
S - Scale & Bottlenecks (Identify and resolve)
A - APIs (Define key interfaces)
D - Data Model (Database schema, choice)
```

### Step 1: Requirements (5 minutes)

**Clarify what you're building.**

**Questions to Ask:**

```
Functional Requirements:
- What are the core features?
- Who are the users?
- What's the primary use case?
- Any specific features to prioritize?
- Mobile, web, or both?

Non-Functional Requirements:
- How many users? (scale)
- How fast should it be? (latency)
- How available? (uptime %)
- Geographic distribution?
- Read vs write ratio?
- Consistency requirements?
- Security considerations?
```

**Example: Design Twitter**

```
âœ“ Good Approach:
"Let me clarify the requirements:
- Can users post tweets (text + media)?
- Can users follow other users?
- Do we need a timeline/feed?
- What about likes, retweets, replies?
- How many daily active users?
- What's the expected tweet volume?
- Any latency requirements for timeline?"

âœ— Poor Approach:
"I'll design Twitter with all features..."
(Jumps into solution without clarifying)
```

### Step 2: Estimation (5 minutes)

**Show you understand scale.**

**Calculate:**
- Daily Active Users (DAU)
- Queries Per Second (QPS)
- Storage requirements
- Bandwidth needs

**Example: Twitter Scale Estimation**

```
Assumptions:
- 500M daily active users (DAU)
- Each user posts 2 tweets/day
- Each user views 100 tweets/day
- Average tweet size: 300 bytes
- 10% tweets have media (1 MB average)

Write Volume (Posts):
- 500M users Ã— 2 tweets = 1B tweets/day
- 1B / (24 Ã— 60 Ã— 60) â‰ˆ 11,500 tweets/second
- Peak (3x): 35,000 tweets/second

Read Volume (Timeline):
- 500M users Ã— 100 tweets = 50B reads/day
- 50B / (24 Ã— 60 Ã— 60) â‰ˆ 580,000 reads/second
- Peak: 1,700,000 reads/second

Storage (per day):
- Text: 1B tweets Ã— 300 bytes = 300 GB
- Media: 100M tweets Ã— 1 MB = 100 TB
- Total: ~100 TB/day
- 5 years: 100 TB Ã— 365 Ã— 5 = 182 PB

Bandwidth:
- Write: 35,000 tweets/s Ã— 300 bytes = 10 MB/s (text)
         + 3,500 media/s Ã— 1 MB = 3.5 GB/s (media)
- Read: 1.7M reads/s Ã— 300 bytes = 510 MB/s
```

**Pro Tips:**
```
- Round numbers for easier calculation
- State your assumptions clearly
- Show your work (interviewers want to see thinking)
- Use powers of 2 (1K = 1000, 1M = 1000K)
- Don't spend too long on exact numbers
```

### Step 3: High-Level Design (15 minutes)

**Draw the big picture.**

**Components to Consider:**
```
- Clients (web, mobile, desktop)
- Load balancer
- API servers
- Database (SQL, NoSQL)
- Cache (Redis, Memcached)
- Message queue (Kafka, RabbitMQ)
- CDN
- Object storage (S3)
- Search service (Elasticsearch)
```

**Example: Twitter High-Level Design**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Clients                        â”‚
â”‚        (Web, iOS, Android)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Load Balancer (DNS)                 â”‚
â”‚      Route to nearest region                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        â”‚        â”‚
        â†“        â†“        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API    â”‚ â”‚   API    â”‚ â”‚   API    â”‚
â”‚ Servers  â”‚ â”‚ Servers  â”‚ â”‚ Servers  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚            â”‚            â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚            â”‚            â”‚
     â†“            â†“            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Timeline â”‚  â”‚ Tweet   â”‚  â”‚ Social  â”‚
â”‚Service  â”‚  â”‚Service  â”‚  â”‚ Graph   â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚            â”‚            â”‚
     â†“            â†“            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Timeline Cache (Redis)         â”‚
â”‚   - Pre-computed timelines          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚            â”‚            â”‚
     â†“            â†“            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Database (Sharded by user_id)    â”‚
â”‚  - Tweets, Users, Followers         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Object Storage (S3)            â”‚
â”‚  - Media files (images, videos)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Data Flow:**

```
1. Post Tweet:
   Client â†’ API â†’ Tweet Service â†’ Database
                               â†’ Fanout to followers
                               â†’ Update timelines (cache)

2. View Timeline:
   Client â†’ API â†’ Timeline Service â†’ Cache (hit)
                                  â†’ Database (miss)
```

### Step 4: Scale & Bottlenecks (10 minutes)

**Identify limitations and optimize.**

**Common Bottlenecks:**

```
1. Database
   - Single point of failure
   - Limited connections
   - Slow queries

   Solutions:
   - Read replicas
   - Sharding
   - Indexing
   - Caching

2. Network
   - High latency
   - Bandwidth limits

   Solutions:
   - CDN
   - Data compression
   - Edge computing

3. Single Server
   - CPU/Memory limits
   - No fault tolerance

   Solutions:
   - Horizontal scaling
   - Load balancing
   - Redundancy

4. Cache
   - Memory limits
   - Cache misses

   Solutions:
   - Distributed cache
   - Eviction policies
   - Multi-level caching
```

**Example: Twitter Bottlenecks**

```
Bottleneck 1: Timeline Generation
Problem: Generating timeline on-demand is slow
        (must query all followed users)

Solution: Fanout on Write
- Pre-compute timelines when tweet is posted
- Store in Redis (fast reads)
- Trade-off: Write amplification

Bottleneck 2: Celebrity Problem
Problem: Celebrities have millions of followers
        Fanout becomes too expensive

Solution: Hybrid Fanout
- Regular users: Fanout on write
- Celebrities: Fanout on read (merge at query time)

Bottleneck 3: Media Storage
Problem: Billions of images/videos
        Expensive to store

Solution:
- Use S3 for storage (cheap, durable)
- CDN for delivery (fast)
- Compress images (WebP format)
- Lazy load thumbnails
```

### Step 5: API Design (5 minutes)

**Define key endpoints.**

**Example: Twitter APIs**

```javascript
// POST /api/v1/tweets
Request:
{
  "text": "Hello world!",
  "mediaIds": ["img123"],
  "replyToId": "tweet456"
}

Response: 201 Created
{
  "id": "tweet789",
  "userId": "user123",
  "text": "Hello world!",
  "createdAt": "2026-01-16T10:30:00Z"
}

// GET /api/v1/timeline
Query params: ?cursor=abc123&limit=20

Response: 200 OK
{
  "tweets": [...],
  "nextCursor": "def456",
  "hasMore": true
}

// POST /api/v1/users/:userId/follow
Response: 201 Created

// GET /api/v1/users/:userId/tweets
Response: 200 OK
{
  "tweets": [...],
  "totalCount": 1234
}
```

### Step 6: Data Model (5 minutes)

**Design database schema.**

**Example: Twitter Schema**

```sql
-- Users
CREATE TABLE users (
  id BIGINT PRIMARY KEY,
  username VARCHAR(50) UNIQUE,
  display_name VARCHAR(100),
  created_at TIMESTAMP
);

-- Tweets
CREATE TABLE tweets (
  id BIGINT PRIMARY KEY,
  user_id BIGINT REFERENCES users(id),
  text VARCHAR(280),
  created_at TIMESTAMP,
  likes_count INT,
  retweets_count INT
);

CREATE INDEX idx_tweets_user_id ON tweets(user_id, created_at DESC);

-- Followers (who follows whom)
CREATE TABLE followers (
  follower_id BIGINT REFERENCES users(id),
  following_id BIGINT REFERENCES users(id),
  created_at TIMESTAMP,
  PRIMARY KEY (follower_id, following_id)
);

CREATE INDEX idx_followers_following ON followers(following_id);

-- Timeline cache (Redis)
Key: timeline:{user_id}
Value: List<tweet_id> (sorted by timestamp)
```

**Database Choice Discussion:**

```
SQL (PostgreSQL):
âœ“ ACID transactions
âœ“ Complex queries (JOINs)
âœ“ Data integrity
âœ— Harder to scale

NoSQL (Cassandra):
âœ“ Easy horizontal scaling
âœ“ High write throughput
âœ“ No single point of failure
âœ— No ACID
âœ— Limited queries

Decision for Twitter:
- Use SQL for social graph (users, followers)
  Reason: Data integrity, complex relationships

- Use NoSQL for tweets (high write volume)
  Reason: Easy sharding, write-heavy

- Use Redis for timeline cache
  Reason: Fast reads
```

---

## 9.3 Common Interview Questions

### Question 1: Design a URL Shortener (Easy)

**Requirements:**
- Convert long URLs to short codes
- Redirect short URLs to original
- Track click statistics

**Key Points:**
```
1. Short Code Generation
   - Base62 encoding (0-9, a-z, A-Z)
   - 7 characters = 62^7 = 3.5T URLs
   - Auto-increment ID â†’ Base62

2. Database
   - SQL: Simple schema
   - Index on short_code

3. Caching
   - Redis for hot URLs
   - 95%+ cache hit rate

4. Scale
   - Read-heavy (100:1 read/write)
   - CDN for redirects
   - Multiple regions
```

**Common Follow-ups:**
- How to handle custom short URLs?
- How to prevent abuse?
- Analytics implementation?
- How to scale to 1B URLs?

### Question 2: Design Instagram (Medium)

**Requirements:**
- Upload/view photos
- Follow users
- Timeline feed
- Like and comment

**Key Points:**
```
1. Image Storage
   - S3 for raw images
   - Multiple sizes (thumbnail, medium, large)
   - CDN for delivery

2. Timeline Generation
   - Fanout on write (like Twitter)
   - Pre-compute feed in Redis

3. Database Sharding
   - Shard by user_id
   - Co-locate user's data

4. Scale
   - 500M photos/day
   - Media storage: TB/day
   - Timeline reads: 100K QPS
```

**Common Follow-ups:**
- How to handle trending posts?
- Search implementation?
- Story feature (24h expiry)?
- Live video streaming?

### Question 3: Design Uber (Hard)

**Requirements:**
- Match riders with drivers
- Real-time location tracking
- Trip management
- Payments

**Key Points:**
```
1. Location Tracking
   - Redis Geospatial for driver locations
   - Update every 5 seconds
   - Quad-tree for spatial indexing

2. Matching Algorithm
   - Find nearest available drivers
   - Price calculation (surge pricing)
   - ETA estimation

3. Real-time Communication
   - WebSockets for location updates
   - Push notifications for matches

4. Consistency
   - One driver, one ride (prevent double booking)
   - Distributed locking
   - Saga pattern for trip lifecycle
```

**Common Follow-ups:**
- Surge pricing implementation?
- How to handle GPS inaccuracy?
- Driver behavior scoring?
- Payment processing?

### Question 4: Design WhatsApp (Hard)

**Requirements:**
- Send/receive messages
- Online status
- Delivered/read receipts
- Group chats
- Media sharing

**Key Points:**
```
1. Real-time Messaging
   - WebSockets for connections
   - Message queue for delivery
   - Store-and-forward if offline

2. Message Storage
   - Cassandra (write-optimized)
   - Shard by user_id
   - TTL for old messages

3. Online Status
   - Redis for presence
   - Heartbeat every 30s

4. Scale
   - 2B users
   - 100B messages/day
   - Availability > consistency
```

**Common Follow-ups:**
- End-to-end encryption?
- Voice/video calls?
- Message sync across devices?
- Group chat with 256 members?

### Question 5: Design Netflix (Hard)

**Requirements:**
- Video streaming
- Recommendations
- User profiles
- Search and browse

**Key Points:**
```
1. Video Delivery
   - Transcoding (multiple qualities)
   - CDN (edge servers)
   - Adaptive bitrate streaming

2. Content Storage
   - S3 for videos
   - Pre-positioning (predict demand)
   - 95%+ cache hit at edge

3. Recommendations
   - ML model for personalization
   - Batch processing (Spark)
   - Cache recommendations

4. Scale
   - 200M subscribers
   - 100M concurrent streams
   - 500 Tbps bandwidth
```

**Common Follow-ups:**
- Adaptive bitrate algorithm?
- Content pre-positioning?
- Recommendation system details?
- Cost optimization?

---

## 9.4 Evaluation Criteria

### What Interviewers Score

```
1. Requirements Gathering (15%)
   - Asks clarifying questions
   - Identifies key features
   - Understands constraints

2. System Architecture (25%)
   - High-level design
   - Component interactions
   - Data flow

3. Scale & Performance (20%)
   - Capacity estimation
   - Bottleneck identification
   - Optimization strategies

4. Data Model (15%)
   - Database choice
   - Schema design
   - Indexing strategy

5. Trade-off Analysis (15%)
   - Discusses alternatives
   - Justifies decisions
   - Understands limitations

6. Communication (10%)
   - Clear explanations
   - Structured approach
   - Collaborative discussion
```

### Red Flags (What NOT to Do)

```
âŒ Jump to solution without clarifying requirements
âŒ Ignore scale/capacity estimation
âŒ Over-engineer (add unnecessary complexity)
âŒ No trade-off analysis
âŒ Single point of failure
âŒ No monitoring/observability
âŒ Ignore the interviewer's hints
âŒ Get defensive about feedback
âŒ Spend too much time on one area
âŒ No fallback for failures
```

### Green Flags (What TO Do)

```
âœ… Start with requirements clarification
âœ… Show your work (calculations, diagrams)
âœ… Think out loud (explain reasoning)
âœ… Start simple, then scale
âœ… Identify bottlenecks proactively
âœ… Discuss trade-offs
âœ… Design for failure
âœ… Listen to interviewer feedback
âœ… Manage time well
âœ… Show real-world knowledge
```

---

## 9.5 Mock Interview Example

**Question: Design a rate limiter**

**Candidate's Approach:**

**Step 1: Clarify Requirements (2 minutes)**

```
Candidate: "Let me clarify the requirements:
- Is this for API rate limiting?
- Should it work across multiple servers (distributed)?
- What are the limits? (e.g., 100 requests per minute?)
- Should different users have different limits?
- Should it be per user, per IP, or both?
- What happens when limit exceeded? Return error?
- Any latency requirements?"

Interviewer: "Yes, distributed API rate limiter.
100 requests per minute per user. Return 429 error
when exceeded. Should add < 10ms latency."
```

**Step 2: High-Level Design (3 minutes)**

```
Candidate: "I'll design a distributed rate limiter:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Gateway    â”‚ â† Rate Limiter Middleware
â”‚                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚Rate Limit â”‚  â”‚
â”‚  â”‚Middleware â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis Cluster  â”‚ â† Distributed counter storage
â”‚  (Centralized)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

For each request:
1. Extract user ID
2. Check Redis counter for user
3. If under limit: increment and allow
4. If over limit: reject with 429
"

Interviewer: "Good. What algorithm will you use?"
```

**Step 3: Algorithm Choice (5 minutes)**

```
Candidate: "I'll compare algorithms:

1. Fixed Window
   - Simple counter per minute
   - Problem: Burst at boundaries

2. Sliding Window
   - More accurate
   - Uses sorted set in Redis
   - My choice for accuracy

3. Token Bucket
   - Allows bursts
   - Good for this use case too

I'll go with Sliding Window for accuracy:

Implementation:
- Key: user:{userId}:requests
- Value: Sorted set (timestamp â†’ request_id)
- TTL: 60 seconds

For each request:
1. Current time: now
2. Window start: now - 60s
3. Remove old entries: ZREMRANGEBYSCORE(key, 0, window_start)
4. Count: ZCARD(key)
5. If count < 100:
   - Add: ZADD(key, now, unique_id)
   - Allow request
6. Else:
   - Reject with 429
"

Interviewer: "Good. But what about performance?
Multiple Redis operations per request?"
```

**Step 4: Optimization (5 minutes)**

```
Candidate: "You're right. Multiple operations are slow.
Let me optimize with Lua script (atomic):

local key = KEYS[1]
local limit = tonumber(ARGV[1])
local window = tonumber(ARGV[2])
local now = tonumber(ARGV[3])

-- Remove old entries
redis.call('ZREMRANGEBYSCORE', key, 0, now - window)

-- Count current
local count = redis.call('ZCARD', key)

if count < limit then
  -- Add new entry
  redis.call('ZADD', key, now, now)
  redis.call('EXPIRE', key, window)
  return 1  -- Allowed
else
  return 0  -- Rejected
end

This makes it a single Redis call, < 5ms latency."

Interviewer: "Great. What about distributed counters?
Multiple API servers might have race conditions."
```

**Step 5: Handle Race Conditions (3 minutes)**

```
Candidate: "Redis operations are atomic, so we're safe.
But I see your point about consistency.

Alternatives:
1. Redis is centralized (single source of truth) âœ“
2. Local counters â†’ sync to Redis (eventual consistency)
   - Faster but less accurate
3. Use Redis cluster with replication
   - High availability

For this use case, centralized Redis is best:
- Accuracy is important (rate limiting)
- 5ms latency is acceptable
- Redis can handle 100K ops/sec

For HA, use Redis Sentinel or Cluster:
- Automatic failover
- Read replicas
"

Interviewer: "Good. One more thing: How would you
handle different limits for different users?"
```

**Step 6: Custom Limits (2 minutes)**

```
Candidate: "I'd add a tier system:

Key structure: user:{userId}:tier

Tiers:
- free: 100 req/min
- premium: 1000 req/min
- enterprise: 10000 req/min

Before checking rate limit:
1. Get user tier from cache/database
2. Apply corresponding limit

Could also use:
- IP-based limits (for anonymous users)
- Endpoint-specific limits (different per API)
- Weighted limits (expensive operations cost more)
"

Interviewer: "Excellent! Any final thoughts on
monitoring and alerting?"
```

**Step 7: Monitoring (1 minute)**

```
Candidate: "For production, I'd monitor:

Metrics:
- Total requests
- Rejected requests (429 rate)
- Average latency
- P99 latency
- Redis health

Alerts:
- Rejection rate > 10% (possible attack)
- Redis latency > 10ms
- Redis connection failures

Logging:
- Log rejected requests (user_id, endpoint)
- Help identify abuse patterns
"
```

**Evaluation:**
```
âœ… Clarified requirements
âœ… Provided high-level design
âœ… Chose appropriate algorithm
âœ… Identified performance issue
âœ… Optimized with Lua script
âœ… Handled edge cases
âœ… Discussed trade-offs
âœ… Added monitoring

Result: Strong Hire
```

---

## 9.6 Time Management

### 45-Minute Interview Timeline

```
0:00 - 0:05   Requirements (5 min)
              - Ask clarifying questions
              - Define scope
              - Note assumptions

0:05 - 0:10   Estimation (5 min)
              - Users, QPS, storage
              - Show calculations
              - State assumptions

0:10 - 0:25   High-Level Design (15 min)
              - Draw architecture diagram
              - Explain data flow
              - Major components

0:25 - 0:40   Deep Dive (15 min)
              - Database schema
              - Scaling strategy
              - Bottleneck resolution
              - API design

0:40 - 0:45   Wrap-up (5 min)
              - Trade-offs
              - Limitations
              - Future improvements
              - Questions
```

**If Running Out of Time:**

```
Priority 1 (Must Cover):
- Requirements
- High-level design
- Main data flow

Priority 2 (Should Cover):
- Capacity estimation
- Database design
- One deep dive topic

Priority 3 (Nice to Have):
- Detailed API design
- Multiple deep dives
- Monitoring strategy
```

**Tips:**
```
âœ“ Watch the clock
âœ“ Ask interviewer to guide focus
âœ“ "Should I go deeper here or move on?"
âœ“ Breadth first, then depth
âœ“ Skip non-critical details
```

---

## 9.7 Communication Tips

### Think Out Loud

```
âŒ Bad: (Silent for 2 minutes, then draws diagram)

âœ… Good: "I'm thinking about the data flow.
Users post tweets, which need to be delivered
to followers. There are two approaches:
fanout-on-write or fanout-on-read.
Let me compare them..."
```

### Use the Whiteboard Effectively

```
âœ“ Draw neatly (boxes for components)
âœ“ Label everything clearly
âœ“ Use arrows to show data flow
âœ“ Include legends if needed
âœ“ Leave space for additions
âœ“ Use different colors (if available)

Example Layout:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client Layer                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Load Balancer                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Application Layer              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Data Layer                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Handle Disagreement

```
âŒ Bad: "No, that won't work because..."

âœ… Good: "That's an interesting point. Let me think
about the trade-offs. Your approach has benefits
X and Y, but might have challenge Z. What if we..."
```

### Ask for Guidance

```
âœ“ "Should I go deeper into database design,
   or would you like me to cover caching first?"

âœ“ "I have two approaches in mind. Would you
   like me to compare them?"

âœ“ "Is this level of detail sufficient, or
   should I elaborate?"
```

---

## 9.8 Common Mistakes to Avoid

### Mistake 1: No Requirements Clarification

```
âŒ Bad: "I'll design Twitter with all features..."
       (Jumps straight into solution)

âœ… Good: "Before I start, let me clarify:
       - Should this support direct messages?
       - What about trending topics?
       - Any specific scale requirements?"
```

### Mistake 2: Ignoring Scale

```
âŒ Bad: Designs for 100 users when problem states
       100 million users

âœ… Good: "With 100M users, a single database won't
       work. I'll need sharding..."
```

### Mistake 3: Over-Engineering

```
âŒ Bad: Adds microservices, Kafka, multiple caches
       for a simple URL shortener

âœ… Good: "I'll start with a simple design, then
       discuss how to scale if needed."
```

### Mistake 4: Single Point of Failure

```
âŒ Bad: Single database, single server, no backups

âœ… Good: "I'll add redundancy: database replicas,
       multiple app servers, load balancer failover"
```

### Mistake 5: No Monitoring

```
âŒ Bad: Doesn't mention monitoring, alerting, logging

âœ… Good: "For production, I'd add:
       - Health checks
       - Metrics (latency, error rate)
       - Alerts for anomalies
       - Distributed tracing"
```

### Mistake 6: Ignoring Trade-offs

```
âŒ Bad: "We'll use NoSQL because it's scalable"
       (No discussion of alternatives)

âœ… Good: "NoSQL gives us scalability but we lose
       ACID transactions. For this use case,
       eventual consistency is acceptable because..."
```

---

## 9.9 Final Preparation Checklist

### Technical Knowledge

```
â–¡ CAP Theorem (Consistency, Availability, Partition Tolerance)
â–¡ Database types (SQL vs NoSQL)
â–¡ Sharding and replication
â–¡ Caching strategies (Redis, Memcached)
â–¡ Load balancing algorithms
â–¡ API design (REST, GraphQL, gRPC)
â–¡ Message queues (Kafka, RabbitMQ)
â–¡ Microservices patterns
â–¡ CDN and edge computing
â–¡ Consistent hashing
â–¡ Rate limiting algorithms
â–¡ Circuit breaker pattern
â–¡ Data structures (trees, graphs, hash tables)
```

### System Design Patterns

```
â–¡ Fanout on write vs fanout on read
â–¡ Event-driven architecture
â–¡ CQRS (Command Query Responsibility Segregation)
â–¡ Saga pattern (distributed transactions)
â–¡ Bulkhead pattern (resource isolation)
â–¡ Service discovery
â–¡ API Gateway
â–¡ Bloom filters
â–¡ Geohashing (location-based services)
```

### Practice Systems

```
â–¡ URL Shortener (Easy)
â–¡ Pastebin (Easy)
â–¡ Instagram (Medium)
â–¡ Twitter (Medium)
â–¡ Netflix (Hard)
â–¡ Uber (Hard)
â–¡ WhatsApp (Hard)
â–¡ YouTube (Hard)
â–¡ Google Drive (Hard)
â–¡ Ticketmaster (Hard)
```

### Numbers to Remember

```
Latency:
- L1 cache: 0.5 ns
- Main memory: 100 ns
- SSD read: 150 Î¼s
- Network (same datacenter): 0.5 ms
- Network (cross-region): 50-100 ms

Availability:
- 99%: 3.65 days/year downtime
- 99.9%: 8.76 hours/year downtime
- 99.99%: 52.56 minutes/year downtime
- 99.999%: 5.26 minutes/year downtime

Throughput:
- Typical server: 1000-10000 RPS
- Redis: 100K ops/sec
- Cassandra: 1M writes/sec
```

---

## 9.10 Resources for Continued Learning

### Books

```
1. "Designing Data-Intensive Applications" by Martin Kleppmann
   - Best book for understanding distributed systems
   - Must-read for senior engineers

2. "System Design Interview â€“ An Insider's Guide" by Alex Xu
   - Structured approach to interviews
   - Many examples

3. "Building Microservices" by Sam Newman
   - Microservices patterns
   - Real-world advice
```

### Online Resources

```
1. System Design Primer (GitHub)
   - Comprehensive overview
   - Flash cards, practice problems

2. High Scalability Blog
   - Real-world architectures
   - Case studies from top companies

3. Engineering Blogs
   - Netflix Tech Blog
   - Uber Engineering Blog
   - Twitter Engineering Blog
   - Meta Engineering Blog
```

### Practice Platforms

```
1. Mock Interviews
   - Practice with peers
   - Record and review
   - Time yourself (45 min)

2. Draw.io / Lucidchart
   - Practice drawing diagrams
   - Get comfortable with tools

3. LeetCode / System Design section
   - Practice problems
   - Community solutions
```

---

## 9.11 Key Takeaways

### The Golden Rules

```
1. Clarify Before You Design
   - Always ask questions
   - Don't assume
   - Understand constraints

2. Start Simple, Then Scale
   - Don't over-engineer
   - Add complexity when needed
   - Justify each decision

3. Think Out Loud
   - Explain your reasoning
   - Make it collaborative
   - Show your thought process

4. Consider Trade-offs
   - Every decision has costs
   - Compare alternatives
   - No perfect solution

5. Design for Failure
   - Everything fails
   - Add redundancy
   - Plan recovery

6. Communicate Clearly
   - Use diagrams
   - Be organized
   - Listen actively

7. Manage Your Time
   - Watch the clock
   - Breadth first
   - Adjust based on feedback
```

### Success Formula

```
Success = Technical Knowledge
        + Structured Approach
        + Clear Communication
        + Trade-off Analysis
        + Real-world Experience
```

### Remember

```
âœ“ There's no one "correct" answer
âœ“ Focus on the journey, not just the destination
âœ“ Show how you think, not just what you know
âœ“ Be collaborative, not defensive
âœ“ It's okay to say "I don't know, but here's how I'd find out"
```

---

## 9.12 Final Thoughts

System design interviews assess your ability to:
- Think at scale
- Make informed trade-offs
- Design resilient systems
- Communicate effectively

**With this guide, you have:**
- âœ… 9 comprehensive chapters
- âœ… 200+ pages of content
- âœ… 100+ code examples
- âœ… 3 complete case studies
- âœ… Interview frameworks and strategies
- âœ… Real-world patterns from top companies

**You're now prepared to:**
- Ace system design interviews at top tech companies
- Design scalable, reliable production systems
- Lead technical discussions and design reviews
- Make informed architectural decisions

---

## ğŸ¯ You're Ready!

**Best of luck with your interviews!** ğŸš€

Remember: System design is a skill that improves with practice. Keep learning, keep practicing, and keep building.

**Questions or Feedback?**
- Review the earlier chapters for deep dives
- Practice with peers
- Learn from real-world systems
- Stay curious

---

**THE END**

*"Good design is as little design as possible."* - Dieter Rams

*"Make it work, make it right, make it fast."* - Kent Beck
